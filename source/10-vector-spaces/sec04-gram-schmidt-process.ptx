<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="sm-gram-schmidt-process">
    <title>Gram-Schmidt Process</title>

    <introduction xml:id="sm-introduction-gram-schmidt-process">
        <p>
            The <term>Gram-Schmidt process</term> is an algorithm used to create an <term>orthonormal</term>
            set from a linearly independent set of vectors.
            An orthonormal set of vectors has two key properties:
            <ul>
                <li>
                    <p>Every vector in the set is orthogonal to every other vector.</p>
                </li>
                <li>
<<<<<<< alex-testing
                    <p>Every vector has a length of 1.</p>
=======
                    <p>
                        Every vector has a length of 1.
                    </p>
>>>>>>> main
                </li>
            </ul>
            
            If we have a set of vectors <m>v_1, v_2, \ldots, v_n</m>, the algorithm can be described as follows. We start with finding the orthogonal set:
        </p>
        <me>u_k = v_k - \sum_{j=1}^{k-1} \mathrm{proj}_{u_j}(v_k)</me>
        <p>
            We then normalize to get the orthonormal set:
        </p>
<<<<<<< alex-testing
        <me>e_k = \frac{u_k}{||u_k||}</me>


    </introduction>
    <subsection xml:id="sm-gram-schmidt-manual">
        <title>Manual Gram-Schmidt Process</title>
        <p>
            We will first implement Gram-Schmidt manually. In the following
            example, we use vectors in <m>\mathbb{R}^4</m>.
        </p>

        <sage>
            <input>
                v1 = vector([1, 1, 1, 1])
                v2 = vector([0, 1, 1, 1])
                v3 = vector([0, 0, 1, 1])
                v1, v2, v3
            </input>
            <output></output>
        </sage>

        <p>Compute the orthogonal set using projections: <m>u_1 = v_1,\quad u_2 = v_2 - \mathrm{proj}_{u_1}(v_2),\quad u_3 = v_3 - \mathrm{proj}_{u_1}(v_3) - \mathrm{proj}_{u_2}(v_3)</m>.</p>

        <sage>
            <input>
                # Step 1
                u1 = v1

                # Step 2: u2 = v2 - proj_u1(v2)
                proj1_2 = (v2.dot_product(u1) / u1.dot_product(u1)) * u1
                u2 = v2 - proj1_2
                # Step 3: u3 = v3 - proj_u1(v3) - proj_u2(v3)
                proj1_3 = (v3.dot_product(u1) / u1.dot_product(u1)) * u1
                proj2_3 = (v3.dot_product(u2) / u2.dot_product(u2)) * u2
                u3 = v3 - proj1_3 - proj2_3

                print("Orthogonal basis (unnormalized):")
                print("u1 =", u1, "||u1|| =", u1.norm())
                print("u2 =", u2, "||u2|| =", u2.norm())
                print("u3 =", u3, "||u3|| =", u3.norm())
            </input>
            <output></output>
        </sage>

        <p>We now normalize to get the orthonormal set: <m>e_i = u_i / ||u_i||</m>.</p>

        <sage>
            <input>
                e1 = u1 / u1.norm()
                e2 = u2 / u2.norm()
                e3 = u3 / u3.norm()
                print("Orthonormal basis:")
                print("e1 =", e1)
                print("e2 =", e2)
                print("e3 =", e3)
            </input>
            <output></output>
        </sage>

        <p>We can easily verify our work by checking the orthogonality of the orthonormal vectors.</p>

        <sage>
            <input>
                print("Checks:")
                print("u1 · u2 =", u1.dot_product(u2))
                print("u1 · u3 =", u1.dot_product(u3))
                print("u2 · u3 =", u2.dot_product(u3))
            </input>
            <output></output>
        </sage>
    </subsection>

    <subsection xml:id="sm-gram-schmidt-builtin">
        <title>Built-in Gram-Schmidt Process</title>
        <p>
            In Sage, the Gram-Schmidt process can be applied to a matrix whose rows 
            form the set of vectors we wish to make orthonormal. 
            Let's start with a basis for a subspace of <m>\mathbb{R}^3</m>.
        </p>
        <sage>
            <input>
                # Define a basis with two linearly independent vectors
                v1 = vector(RDF, [1, 1, 0]) # Sage does not support the Gram-Schmidt process with RR real numbers so we must use RDF real numbers
                v2 = vector(RDF, [1, 2, 2])
                
=======
        <p>
            In Sage, the Gram-Schmidt process can be applied to a matrix whose rows
            form the set of vectors we wish to make orthonormal.
            Let's start with a basis for a subspace of <m>\R^3</m>.
        </p>
        <sage>
            <input>
                # Define a basis with two linearly independent vectors
                v1 = vector(RDF, [1, 1, 0]) # Sage does not support the Gram-Schmidt process
                v2 = vector(RDF, [1, 2, 2]) # with RR real numbers so we must use RDF real numbers

>>>>>>> main
                # Create a matrix with these vectors as rows
                A = matrix([v1, v2])
                A
            </input>
<<<<<<< alex-testing
            <output></output>
        </sage>
        <p>
            Now, we apply the <c>gram_schmidt</c> method. 
=======
        </sage>
        <p>
            Now, we apply the <c>gram_schmidt</c> method.
>>>>>>> main
            The <c>orthonormal=True</c>
            argument ensures the resulting vectors are normalized to have unit length.
        </p>
        <sage>
            <input>
                B, mu = A.gram_schmidt(orthonormal=True)
                B
            </input>
<<<<<<< alex-testing
            <output></output>
        </sage>
        <p>
            The matrix <m>B</m> contains the new basis as row vectors, 
            while the matrix <m>mu</m>
=======
        </sage>
        <p>
            The matrix <m>B</m> contains the new basis as row vectors,
            while <m></m> the matrix <m>mu</m>
>>>>>>> main
            contains the coefficients used in the Gram-Schmidt Process.
        </p>
        <p>
            Let's extract the new basis vectors and verify their properties.
        </p>
        <p>
            First we will extract the vectors:
        </p>
        <sage>
            <input>
                u1 = B.row(0)
                u2 = B.row(1)
                print(u1)
                print(u2)
            </input>
<<<<<<< alex-testing
            <output></output>
=======
>>>>>>> main
        </sage>
        <p>
            Now we will use the dot product to check orthogonality.
        </p>
        <sage>
            <input>
                u1.dot_product(u2)
            </input>
<<<<<<< alex-testing
            <output></output>
=======
>>>>>>> main
        </sage>
        <p>
            Then we must ensure that they are normalized.
        </p>
        <sage>
            <input>
                print(f"{u1.norm() = }\n{u2.norm() = }")
            </input>
<<<<<<< alex-testing
            <output></output>
=======
>>>>>>> main
        </sage>
        <note>
            <title>Floating Point Approximation</title>
            <p>
<<<<<<< alex-testing
                The results here are only near their expected values 
                due to accumulated floating point errors.
                If one wants to avoid these issues, 
                Sage offers the algebraic field, <c>QQbar</c>,
                which contains all rational numbers and many irrational numbers 
                (but notably missing <m>\pi</m> and <m>e</m>).
            </p>
        </note>
    </subsection>

=======
                The results here are only near their expected values
                due to accumulated floating point errors.
                If one wants to avoid these issues,
                Sage offers the algebraic field, <c>QQbar</c>,
                which contains all rational numbers and many irrational numbers
                (but notably missing <m>\pi</m> and <m>e</m>).
            </p>
        </note>
    </introduction>
>>>>>>> main
</section>
